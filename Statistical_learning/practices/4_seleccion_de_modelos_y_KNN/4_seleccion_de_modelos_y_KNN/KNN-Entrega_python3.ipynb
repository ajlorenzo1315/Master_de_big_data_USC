{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "#### Boletín 1: evaluación y selección de modelos\n",
    "#### Boletín 2: métodos basados en vecinos más próximos\n",
    "\n",
    "Para la realización de las prácticas de esta segunda parte de la materia se utilizará scikit-learn, una\n",
    "librería de aprendizaje estadístico en Python, a través de Jupyter Notebooks. La ejecución se realizará\n",
    "en el CESGA siguiendo los pasos indicados en el archivo CESGA.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[introduction.ipynb](http://localhost:8888/notebooks/4_seleccion_de_modelos_y_KNN/Introduction.ipynb)**\n",
    "\n",
    "    En primer lugar, abre mediante ipython notebook el fichero introduction.ipynb, donde se describen algunas de las operaciones básicas necesarias para trabajar con scikit-learn: aprenderás a cargar los datos, realizar operaciones básicas con matrices, y representaciones gráficas.\n",
    "\n",
    "**[knn.ipynb](http://localhost:8888/notebooks/4_seleccion_de_modelos_y_KNN/KNN.ipynb)**\n",
    "\n",
    "    A continuación abre el fichero knn.ipynb. En este archivo se realiza la experimentación con un algoritmo sobre un conjunto de datos. Concretamente, se ha escogido el método de vecinos más cercanos, y un archivo con un problema muy simple (toyExample.data). Los pasos que se realizan son los siguientes:\n",
    "    \n",
    "    - Carga de datos y preprocesado básico.\n",
    "    - División del conjunto de datos en entrenamiento y test.\n",
    "    - Generación de los datos sobre los que se harán las representaciones gráficas.\n",
    "    - Búsqueda de los mejores valores para los hiper-parámetros mediante validación cruzada.\n",
    "    - Generación del modelo final, test y representación gráfica.\n",
    "    - Guardar el modelo aprendido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones para la experimentación en TODOS los boletines de prácticas\n",
    "\n",
    "En los diferentes ejercicios que se realizarán durante el curso, existen una serie de operaciones con una componente aleatoria: la división en entrenamiento y test, el aprendizaje de un modelo o incluso, en\n",
    "algunos casos, el test del modelo. Como norma general de experimentación es interesante asegurar la repetibilidad de los experimentos, eliminando la aleatoriedad, puesto que nos permite depurar errores,\n",
    "comparar modelos, etc. Además, para la evaluación de los boletines también es imprescindible eliminar esa aleatoriedad.\n",
    "\n",
    "Para ello vamos a fijar la semilla del generador de números aleatorios, de tal manera que su secuencia sea siempre la misma. La semilla se establece mediante el comando np.random.seed(SEED_VALUE), y\n",
    "en este boletín utilizaremos un SEED_VALUE=1. Será necesario utilizar este comando inmediatamente antes de cualquier operación con un componente aleatorio. Esto incluye: train_test_split(), fit(),\n",
    "predict(), etc. En aquellas funciones que lo admitan, sustituiremos el comando np.random.seed(SEED_VALUE) por el argumento random_state=SEED_VALUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "#np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)  # Para evitar warnings en algunas gráficas\n",
    "import warnings\n",
    "\n",
    "# Filtrar y ocultar todos los warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = './data/Exercice.data'\n",
    "DATASET_DELIMITER = ','\n",
    "SEED_VALUE = 1  # NO CAMBIES ESTA SEMILLA, así todos tendremos los mismos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Dado el siguiente conjunto de datos de clasificación con 6 observaciones, 3 variables de entrada y\n",
    "una variable de salida:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos el fichero de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(DATASET_NAME):\n",
    "    dataset = pd.read_csv(DATASET_NAME, \n",
    "                          delimiter=DATASET_DELIMITER,\n",
    "                          skiprows=0,\n",
    "                          header=None,\n",
    "                          names = [\"X1\", \"X2\", \"X3\", \"Y\"])\n",
    "else:\n",
    "    dataset = d.DataFrame(np.array(\n",
    "    [[0, 3, 2, 1], \n",
    "    [3, 0, 3, 0], \n",
    "    [0, 3, -1, 0], \n",
    "    [3, 0, 0, 1], \n",
    "    [1, 2, 1, 1], \n",
    "    [2, 1, 0, 0]]), columns=['X1', 'X2', 'X3', 'Y'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero contiene 3 variables y 17 observaciones distintas. Las variables predictoras son `X0` y `X1`, y la variable dependiente sería `Y`. Estamos ante un problema de clasificación binario (dada la naturaleza booleana de `Y`, existen 2 clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "columns = dataset.columns[:-1]  # Exclude the 'Y' column\n",
    "\n",
    "# Create a 2x3 subplot grid for both histogram and scatter plots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Visualize histograms for the first three columns\n",
    "for i, column in enumerate(columns[:3]):\n",
    "    axs[0, i].hist([dataset[dataset['Y'] == 1][column], dataset[dataset['Y'] == 0][column]], label=['1', '0'], bins=20, alpha=0.7)\n",
    "    axs[0, i].set_title(\"Histogram of {}\".format(column))\n",
    "    axs[0, i].legend(loc='upper right')\n",
    "\n",
    "# Create combinations of variables for scatter plot comparison\n",
    "combinations = list(itertools.combinations(columns, 2))\n",
    "\n",
    "# Visualize scatter plots for the remaining combinations\n",
    "for j, (var1, var2) in enumerate(combinations):\n",
    "    k = j + 1  # Start from the second row\n",
    "    scatter1 = axs[1, j].scatter(dataset[dataset['Y'] == 1][var1], dataset[dataset['Y'] == 1][var2], c='red', label='1')\n",
    "    scatter0 = axs[1, j].scatter(dataset[dataset['Y'] == 0][var1], dataset[dataset['Y'] == 0][var2], c='blue', label='0')\n",
    "    axs[1, j].set_title(\"{} vs {}\".format(var1, var2))\n",
    "    axs[1, j].set_xlabel(var1)\n",
    "    axs[1, j].set_ylabel(var2)\n",
    "    axs[1, j].legend(handles=[scatter1, scatter0], loc='upper right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo que se quiere hacer la predicción de la variable de salida para X1=0, X2=0, X3=0\n",
    "mediante KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos nuestro punto para la prediccion\n",
    "point=np.array([0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Computar la distancia entre cada observación y el punto de test.\n",
    "\n",
    "Usamos la distancia euclidania para este calculo\n",
    "\n",
    "$$\n",
    "\\text{distances} = \\sqrt{\\sum_{i=1}^{3} (\\text{dataset}[:, i] - \\text{point}[i])^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distance for each observation\n",
    "distances = np.sqrt(np.sum((dataset[['X1', 'X2', 'X3']] - point) ** 2, axis=1))\n",
    "# Create a DataFrame to display the distances\n",
    "distance_df = pd.DataFrame({\n",
    "    'Observacion': dataset.apply(lambda row: '({}, {}, {})'.format(row[\"X1\"], row[\"X2\"], row[\"X3\"]), axis=1),\n",
    "    'Etiqueta_Observacion': dataset['Y'],\n",
    "    'Punto': dataset.apply(lambda row: '({}, {}, {})'.format(point[0], point[1], point[2]), axis=1),\n",
    "    'Distancia_Euclidiana': distances\n",
    "})\n",
    "\n",
    "# visualizarlo de manera vonita\n",
    "display(distance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** este ejercicio debe hacerse sin utilizar ninguna función de scikit-learn. No es necesario\n",
    "estandarizar las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota: este ejercicio debe hacerse sin utilizar ninguna función de scikit-learn. No es necesario estandarizar las variables\n",
    "# Creamos nuestra propia función KNeighborsClassifier para no usar scikit-learn\n",
    "\n",
    "def knn_classifier(X_train, y_train, X_test, K):\n",
    "    \"\"\"\n",
    "    Clasificación KNN personalizada para un valor de K dado.\n",
    "    \n",
    "    Args:\n",
    "    X_train (numpy.ndarray): Conjunto de entrenamiento (características).\n",
    "    y_train (numpy.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "    X_test (numpy.ndarray): Puntos de prueba (características) a clasificar.\n",
    "    K (int): Número de vecinos cercanos a considerar.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Predicciones para los puntos de prueba.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for test_point in X_test:\n",
    "        # Calcula las distancias euclidianas entre el punto de prueba y todos los puntos de entrenamiento\n",
    "        distances = np.sqrt(np.sum((X_train - test_point) ** 2, axis=1))\n",
    "        \n",
    "        # Encuentra los índices de los K vecinos más cercanos\n",
    "        nearest_indices = np.argsort(distances)[:K]\n",
    "        # Obtiene las etiquetas de los K vecinos más cercanos\n",
    "        nearest_labels = y_train[nearest_indices]\n",
    "        \n",
    "        # Realiza una predicción basada en la mayoría de votos de los vecinos cercanos\n",
    "        prediction = np.bincount(nearest_labels).argmax()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparamos la salida de scikit-learn para comprobar que nuestra funcion esta bien\n",
    "point_test=np.array([[0,0,0]]) \n",
    "X = dataset[['X1', 'X2', 'X3']]\n",
    "y = dataset['Y']\n",
    "\n",
    "# Valores de K para probar\n",
    "k_values = [1,2,3,4,5]\n",
    "\n",
    "# Almacenar resultados de precisión\n",
    "accuracy_custom_knn = []\n",
    "accuracy_sklearn_knn = []\n",
    "\n",
    "# Evaluar diferentes valores de K\n",
    "for K in k_values:\n",
    "    # Usar nuestra función personalizada de KNN\n",
    "    predictions_custom_knn = knn_classifier(X, y, point_test, K)\n",
    "    accuracy_custom_knn.append(predictions_custom_knn)\n",
    "    \n",
    "    # Usar la implementación de scikit-learn de KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)\n",
    "    knn.fit(X, y)\n",
    "    predictions_sklearn_knn = knn.predict(point_test)\n",
    "    accuracy_sklearn_knn.append(predictions_sklearn_knn)\n",
    "\n",
    "accuracy_custom_knn=np.array(accuracy_custom_knn)\n",
    "accuracy_sklearn_knn=np.array(accuracy_sklearn_knn)\n",
    "valores_distintos = np.setxor1d(accuracy_custom_knn, accuracy_sklearn_knn)\n",
    "print(\"KNN custom\",accuracy_custom_knn.T)\n",
    "print(\"KNN sklearn\",accuracy_custom_knn.T)\n",
    "print(\"Son iguales: \",valores_distintos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que demuestra es que tiene un comportamiento similar por lo que podemos usarla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** ¿Cuál es la predicción para K=1? ¿Por qué?\n",
    "\n",
    "Como podemos observar se etiqueta como 0. Puesto que en la tabla que antes generamos se pude observar el punto mas cercano al punto test es el (2,1,0) que está etiquetado como 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn_classifier(X,y,point_test,1)\n",
    "# comparamos la salida de scikit-learn para comprobar que nuestra funcion esta bien\n",
    "print('Prediction for K=1: {}'.format(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** ¿Cuál es la predicción para K=3? ¿Por qué?\n",
    "\n",
    "Como podemos observar se etiqueta como 1. Puesto que en la tabla que antes generamos se pude observar los 3 punto mas cercano al punto test son el (2,1,0) que está etiquetado como 0 (1,2,1) que está etiquetado como 1 y el (3,0,0) que está etiquetado como 1, por lo que haber 2 vecinos etiquetados como 1 etiqueta el punto como 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn_classifier(X,y,point_test,3)\n",
    "\n",
    "print('Prediction for K=3: {}'.format(prediction[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Dado el problema de clasificación [Blood Transfusion Service Center](https://archive.ics.uci.edu/dataset/176/blood+transfusion+service+center):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)Analiza las características del conjunto de datos: número y tipo de variables de entrada y\n",
    "salida, número de instancias, número de clases y distribución de las mismas, correlación\n",
    "entre las variables, valores perdidos, etc.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos el fichero de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_BLOOD='./data/blood+transfusion+service+center/bloodTransfusion.data'\n",
    "# Leer el archivo de datos y obtener la primera fila como nombres de columnas\n",
    "data = pd.read_csv(DATASET_BLOOD)\n",
    "NAME_BLOOD = data.columns.tolist()\n",
    "\n",
    "NAME_BLOOD=[\"Reciente\",\"Frecuencia\",\"Cantidad_Sangre\",\"Tiempo\",\"Donacion_marzo\"]\n",
    "if os.path.exists(DATASET_BLOOD):\n",
    "    dataset = pd.read_csv(DATASET_BLOOD, \n",
    "                          delimiter=DATASET_DELIMITER,\n",
    "                          skiprows=1,\n",
    "                          header=None,\n",
    "                          names = NAME_BLOOD)\n",
    "else:\n",
    "    dataset = d.DataFrame(np.array(\n",
    "    [[0, 3, 2, 1], \n",
    "    [3, 0, 3, 0], \n",
    "    [0, 3, -1, 0], \n",
    "    [3, 0, 0, 1], \n",
    "    [1, 2, 1, 1], \n",
    "    [2, 1, 0, 0]]), columns=['X1', 'X2', 'X3', 'Y'])\n",
    "    \n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tipo del dato de cada columna:')\n",
    "print(dataset.dtypes)\n",
    "# Comprobamos si hay nan\n",
    "print(\"\\n Cantidad de valores NaN en cada columna:\")\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cada columna de este DataFrame representa la siguiente información:\n",
    "\n",
    "- Reciente (Recency (months)): el número de meses que han pasado desde la última donación.\n",
    "- Frecuencia (Frequency (times)): el número total de donaciones de esta persona.\n",
    "- Cantidad_Sangre (Monetary (c.c. blood)): cantidad total de sangre donada en centímetros cúbicos (c.c.).\n",
    "- Tiempo (Time (months)): el número de meses desde la primera donación de esta persona.\n",
    "- Donacion_marzo (whether he/she donated blood in March 2007): la variable a predecir, que nos indica si esta persona donó o no en Marzo de 2007 (1 significa que donó mientras que 0 indica que no donó).\n",
    "\n",
    "siendo la cantidad de instancias dentro del dataset de 748\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir la columna de la etiqueta\n",
    "columns = dataset.columns[:-1]\n",
    "\n",
    "# Crear una cuadrícula de subtramas 2x4 para histogramas y gráficos de dispersión\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Visualizar histogramas para todas las columnas\n",
    "for i, column in enumerate(columns):\n",
    "    axs[i].hist([dataset[dataset['Donacion_marzo'] == 1][column], \n",
    "                    dataset[dataset['Donacion_marzo'] == 0][column]], \n",
    "                   label=['1', '0'], bins=20, alpha=0.7)\n",
    "    axs[i].set_title(\"Histogram of {}\".format(column))\n",
    "    axs[i].legend(loc='upper right')\n",
    "# Ajustar el diseño\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear todas las combinaciones posibles de pares de variables\n",
    "combinations = list(itertools.combinations(columns, 2))\n",
    "\n",
    "# Calcular el número de filas necesario para acomodar todas las combinaciones\n",
    "num_combinations = len(combinations)\n",
    "num_rows = num_combinations // 3 + (num_combinations % 3 > 0)\n",
    "\n",
    "# Crear una cuadrícula de subtramas con un número suficiente de filas para todas las combinaciones\n",
    "fig, axs = plt.subplots(num_rows, 3, figsize=(20, num_rows * 5))  # Ajustar el tamaño de figura según sea necesario\n",
    "\n",
    "# Visualizar gráficos de dispersión para todas las combinaciones\n",
    "for j, (var1, var2) in enumerate(combinations):\n",
    "    row = j // 3\n",
    "    col = j % 3\n",
    "    axs[row, col].scatter(dataset[dataset['Donacion_marzo'] == 1][var1], \n",
    "                          dataset[dataset['Donacion_marzo'] == 1][var2], \n",
    "                          c='red', label='1')\n",
    "    axs[row, col].scatter(dataset[dataset['Donacion_marzo'] == 0][var1], \n",
    "                          dataset[dataset['Donacion_marzo'] == 0][var2], \n",
    "                          c='blue', label='0')\n",
    "    axs[row, col].set_title(\"{} vs {}\".format(var1, var2))\n",
    "    axs[row, col].set_xlabel(var1)\n",
    "    axs[row, col].set_ylabel(var2)\n",
    "    axs[row, col].legend(loc='upper right')\n",
    "\n",
    "# Ajustar el diseño para que no haya superposición\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Nota**\n",
    "\n",
    "- **Desequilibrio de Clases**: La primera fila de histogramas muestra un claro desequilibrio de clases entre aquellos que donaron sangre en marzo de 2007 (etiqueta '1') y aquellos que no lo hicieron (etiqueta '0'). Esto puede afectar el rendimiento del modelo de aprendizaje automático, ya que puede sesgarse hacia la clase más frecuente. Se recomienda aplicar técnicas de balanceo de clases como sobremuestreo, submuestreo o generación de datos sintéticos para manejar este desequilibrio.\n",
    "\n",
    "- **Relación entre 'Frequency' y 'Monetary'**: La correlación directa entre 'Frequency' y 'Monetary' es evidente en el gráfico de dispersión de la esquina inferior derecha, lo que indica una relación lineal casi perfecta. Esto es coherente con la naturaleza de las variables, dado que 'Monetary' es probablemente un múltiplo de 'Frequency' (cada donación tiene un volumen fijo de sangre). Esto sugiere que una de las dos variables podría ser redundante para el modelado predictivo, y se podría considerar eliminar una para simplificar el modelo sin perder información significativa.\n",
    "\n",
    "- **Posible correlación entre 'Time' y otras variables**: Los gráficos de dispersión 'Reciente vs Tiempo' y 'Frecuencia vs Tiempo' no muestran una relación lineal clara, pero sí sugieren algún tipo de relación. Por ejemplo, en 'Reciente vs Tiempo', hay una tendencia de que aquellos con valores más bajos de 'Reciente' tienen una distribución más amplia en 'Tiempo', lo que podría sugerir que los donantes nuevos tienden a tener un historial más corto de donaciones. Sin embargo, esta observación necesita ser investigada más a fondo, posiblemente con análisis estadísticos para establecer la fuerza y la significancia de la correlación.\n",
    "\n",
    "- **Dispersión de los datos**: Hay una dispersión considerable en los datos, especialmente en los gráficos de dispersión 'Reciente vs Frecuencia' y 'Reciente vs Cantidad_Sangre', lo que podría indicar que la variable 'Reciente' tiene una relación menos directa con la frecuencia y la cantidad de donaciones en comparación con la relación entre 'Frecuencia' y 'Cantidad_Sangre'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA:** como observalos la relación entre 'Frequency' y 'Monetary' se podría hacer una reducción dimensional para mejorar el funconamiento de KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Una de las clases que implementa el algoritmo KNN en scikit-learn sklearn.neighbors.KNeighborsClassifier. Revisa los parámetros y métodos que tiene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El [sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) en scikit-learn es un clasificador que implementa la votación de los k-vecinos más cercanos. Aquí están sus parámetros y métodos basados en la documentación oficial de scikit-learn:\n",
    "\n",
    "Parámetros:\n",
    "\n",
    "- `n_neighbors` (int, por defecto=5): Número de vecinos a utilizar para consultas de kneighbors.\n",
    "- `weights` ({'uniform', 'distance'} o callable, por defecto='uniform'): Función de peso utilizada en la predicción.\n",
    "- `algorithm` ({'auto', 'ball_tree', 'kd_tree', 'brute'}, por defecto='auto'): Algoritmo utilizado para calcular los vecinos más cercanos.\n",
    "- `leaf_size` (int, por defecto=30): Tamaño de hoja pasado a BallTree o KDTree.\n",
    "- `p` (float, por defecto=2): Parámetro de potencia para la métrica de Minkowski.\n",
    "- `metric` (str o callable, por defecto='minkowski'): La métrica de distancia a utilizar para el árbol.\n",
    "- `metric_params` (dict, por defecto=None): Argumentos adicionales de palabras clave para la función métrica.\n",
    "- `n_jobs` (int, por defecto=None): El número de trabajos paralelos a ejecutar para la búsqueda de vecinos.\n",
    "\n",
    "Métodos:\n",
    "\n",
    "- `fit`(X, y): Ajustar el clasificador a partir del conjunto de datos de entrenamiento.\n",
    "- `get_metadata_routing`(): Obtener el enrutamiento de metadatos del objeto.\n",
    "- `get_params`([deep]): Obtener los parámetros para este estimador.\n",
    "- `kneighbors`([X, n_neighbors, return_distance]): Encontrar los K-vecinos de un punto.\n",
    "- `kneighbors_graph`([X, n_neighbors, mode]): Calcular el grafo (ponderado) de k-Vecinos para los puntos en X.\n",
    "- `predict`(X): Predecir las etiquetas de clase para los datos proporcionados.\n",
    "- `predict_proba`(X): Devolver las estimaciones de probabilidad para los datos de prueba X.\n",
    "- `score`(X, y[, sample_weight]): Devolver la precisión media en los datos de prueba y etiquetas proporcionados.\n",
    "- `set_params`(**params): Establecer los parámetros de este estimador.\n",
    "- `set_score_request`(*[, sample_weight]): Solicitar metadatos pasados al método `score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     15,
     31
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "# Create a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=2, random_state=42)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define hyperparameters to test\n",
    "n_neighbors_options = [3, 5, 10]\n",
    "weights_options = ['uniform', 'distance']\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for n_neighbors in n_neighbors_options:\n",
    "    for weights in weights_options:\n",
    "        # Create and fit the model\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results.append((n_neighbors, weights, accuracy))\n",
    "\n",
    "# Print results\n",
    "for n_neighbors, weights, accuracy in results:\n",
    "    print(\"n_neighbors: {}, weights: {}, Accuracy: {:.2f}\".format(n_neighbors, weights, accuracy))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** División de los datos en entrenamiento (80%) y test (20%):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**MUY IMPORTANTE:**</span> Vamos a establecer una semilla con un valor predefinido inmediatamente antes de ejecutar cualquier operación con un componente aleatorio. Así aseguramos que nuestros resultados sean repetibles.\n",
    "\n",
    "Esto es, vamos a poner `np.random.seed(SEED_VALUE)` antes de:\n",
    " - `fit()`\n",
    " - `predict()`\n",
    " \n",
    "En aquellas funciones que lo admitan, sustituiremos el comando np.random.seed(SEED_VALUE) por el argumento `random_state=SEED_VALUE`. Por ejemplo, para la división de datos entre entrenamiento y test con `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tenemos mas ejemplos de una categoria que en otra si queremos hacer una experimentación para el conjunto de test \n",
    "# con stratify mantenga el mismo poncentaje de cadad clase  en el test y en el train en este \n",
    "# caso es para que train si hay 2 categorias mantenga la proporcion de estas en train y test decir que si en el total \n",
    "# tenemos 60% 1 y 40% 2 se intenta man tener el porcentaje de dataos \n",
    "dataset_train, dataset_test = train_test_split(dataset,\n",
    "                            test_size=0.2, random_state=SEED_VALUE,\n",
    "                                              stratify=dataset[\"Donacion_marzo\"])\n",
    "print(dataset_test.shape)\n",
    "display(dataset_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, nuestro dataset no tiene valores faltantes.\n",
    "Sin embargo, la sustitución de las variables predictoras por la media se llevaría a cabo de la siguiente manera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp = SimpleImputer(missing_values=np.nan, fill_value='mean')\n",
    "#imp = imp.fit(dataset_train)  # La media la calculamos SÓLO a partir del conjunto de train\n",
    "\n",
    "# Los valores van a ser los mismos que antes, pues no tenemos datos faltantes\n",
    "#dataset_train_prep = imp.transform(dataset_train)\n",
    "#dataset_test_prep = imp.transform(dataset_test)\n",
    "\n",
    "#dataset_test_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleImputer` ha convertido nuestros valores a un array NumPy, por lo que sería bueno que los volviéramos a convertir en formato dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset_train = pd.DataFrame(dataset_train_prep,\n",
    "#                             columns=dataset_train.columns,\n",
    "#                             index=dataset_train.index)\n",
    "#dataset_test = pd.DataFrame(dataset_test_prep,\n",
    "#                            columns=dataset_test.columns,\n",
    "#                            index=dataset_test.index)\n",
    "\n",
    "#dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de variables predictoras y dependientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train_X = dataset_train.loc[:, NAME_BLOOD[:-1]].astype(float)\n",
    "dataset_train_Y = dataset_train.loc[:, NAME_BLOOD[-1]]\n",
    "\n",
    "print(\"dimension:\",dataset_train_X.shape)\n",
    "display(dataset_train_X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_test_X = dataset_test.loc[:, NAME_BLOOD[:-1]].astype(float)\n",
    "dataset_test_Y = dataset_test.loc[:, NAME_BLOOD[-1]]\n",
    "\n",
    "print(\"dimension:\",dataset_train_X.shape)\n",
    "display(dataset_test_X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto hay que hacerlo **DESPUÉS** de dividir en conjuntos de entrenamiento y test.\n",
    "\n",
    "Además, como es un problema de clasificación, **NO** estandarizaremos la variable dependiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(dataset_train_X)\n",
    "\n",
    "dataset_train_X_scaled = scaler.transform(dataset_train_X)\n",
    "dataset_test_X_scaled = scaler.transform(dataset_test_X)\n",
    "\n",
    "#dataset_test_X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los valores con los que se ha estandarizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean {}: {}  |  std {}: {}\".format(NAME_BLOOD[:-1],scaler.mean_, NAME_BLOOD[:-1],scaler.scale_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezamos con la experimentación de KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visualizado y preprocesado los datos. Vamos a empezar a trabajar con nuestro predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos un rango de hiperparámetros para realizar las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(1, 598, 1),\n",
    "    'weights': ['uniform', 'distance'],  # 'callable' no es un valor literal válido, se debe reemplazar con una función concreta si se desea usar.\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': range(1, 50),  # Por ejemplo, valores entre 1 y 50. El valor óptimo puede variar dependiendo del tamaño del conjunto de datos.\n",
    "    'p': [1, 2],  # 1 corresponde a la distancia de Manhattan y 2 a la distancia euclidiana.\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan'],  # Puedes agregar más métricas compatibles con tu conjunto de datos.\n",
    "    # 'metric_params': None,  # Este es un diccionario de parámetros adicionales para la función métrica y su estructura dependerá de la métrica específica que estés utilizando.\n",
    "    'n_jobs': [-1]  # Utilizar -1 para usar todos los procesadores disponibles y acelerar la búsqueda.\n",
    "}\n",
    "# hay que llegar en los extremos las graficas de aqui pued ser minimo local y hay que exporara un poco mas\n",
    "\n",
    "# Expected n_neighbors <= n_samples,  n_samples = 477\n",
    "# Si solo necesitas el número de muestras\n",
    "n_samples = dataset_train_X_scaled.shape[0]\n",
    "\n",
    "# ('Numero de muestras:', 598) auque pone este valor al usar  GridSearchCV me indica que son 477 en el\n",
    "# cesga usamos 130 ya que en este caso comprobamos en el portatil que se comporta de manera similar\n",
    "print(\"Numero de muestras:\", n_samples)\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(1, 130, 1),\n",
    "    'n_jobs': [-1]  # Utilizar -1 para usar todos los procesadores disponibles y acelerar la búsqueda.\n",
    "}\n",
    "# hay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comenzamos las pruebas con 5-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh = KNeighborsClassifier()\n",
    "modelCV = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=5,\n",
    "                       scoring='accuracy', # parametro  top mejores en regresion mean scare error(skle pueda dar - std)\n",
    "                       return_train_score=True)  # El warning es normal, pues el ejemplo es demasiado pequeño\n",
    "\n",
    "np.random.seed(SEED_VALUE)  # Por como funciona KNN, no haría falta establecer una semilla. Pero lo ponemos igualmente\n",
    "modelCV.fit(dataset_train_X_scaled, dataset_train_Y)  # En KNN no hay aprendizaje en sí, pero hay que ejecutar este comando para poder hacer inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_train_class.pkl', 'wb') as f:\n",
    "    pickle.dump(modelCV, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra la gráfica del error de entrenamiento con validación cruzada (5-CV) frente al valor\n",
    "del hiper-parámetro.\n",
    "**¿Cuál es el menor error de validación cruzada, su desviación estándar\n",
    "y el valor del hiper-parámetro para el que se consigue? ¿Cuál es el valor del hiper-\n",
    "parámetro si se aplicase la regla de una desviación estándar? En caso de que haya varios\n",
    "modelos con error mínimo, debe seleccionarse siempre el más simple (cuantos mas vecinos mas simple por que la frontera de decisión es mas suave).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados obtenidos en 5-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse el ranking de los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(modelCV.cv_results_)\n",
    "cv_results.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores hiperparámetros en validación serían los siguientes (aunque no siempre conviene quedarse con los mejores):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results[cv_results['rank_test_score'] == 1]\n",
    "cv_results_best.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfica de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los pesos basados en cada \n",
    "cv_results_uniform = cv_results\n",
    "\n",
    "plt.figure(figsize=(16, 5))  # Puedes cambiar estos valores según tus necesidades\n",
    "# eje x xantidad de vecinos y en el y cuanto es el errror\n",
    "plt.title(\"Error de validacion\")\n",
    "plt.errorbar(cv_results_uniform['param_n_neighbors'],1 - cv_results_uniform['mean_test_score'],\n",
    "             cv_results_uniform['std_test_score'], label='default', capsize=3)  # 1 - [] para imprimir el error\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados obtenidos en 5-CV\n",
    "cv_results = pd.DataFrame(modelCV.cv_results_)\n",
    "# Guardar los resultados completos en un archivo CSV\n",
    "cv_results.to_csv('cv_results.csv', index=False)\n",
    "\n",
    "# Filtrar y guardar los mejores resultados\n",
    "cv_results_best = cv_results[cv_results['rank_test_score'] == 1]\n",
    "cv_results_best.to_csv('cv_results_best.csv', index=False)\n",
    "\n",
    "# Separar los resultados por tipo de peso y guardarlos\n",
    "cv_results_uniform = cv_results\n",
    "cv_results_uniform.to_csv('cv_results_uniform.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results[cv_results['rank_test_score'] == 1].sort_values(by='param_n_neighbors')\n",
    "cv_results_best.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplicar la regla de una desviación estándar\n",
    "best_model = cv_results[cv_results['rank_test_score'] == 1].sort_values(by='param_n_neighbors').iloc[0]\n",
    "mejor_score = best_model['mean_test_score']\n",
    "mejor_std = best_model['std_test_score']\n",
    "\n",
    "\n",
    "threshold =  mejor_score -  mejor_std\n",
    "\n",
    "cv_results_aux = cv_results[\n",
    "     cv_results['mean_test_score']>= threshold\n",
    "].sort_values(by='param_n_neighbors', ascending=False)\n",
    "\n",
    "cv_results_aux = cv_results_aux.loc[:, [\n",
    "    'param_n_neighbors',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'rank_test_score'\n",
    "    ]\n",
    "]\n",
    "\n",
    "cv_results_aux = cv_results_aux.sort_values(by='param_n_neighbors',ascending=False)\n",
    "display(cv_results_aux.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results_aux = cv_results_aux.sort_values(by='param_n_neighbors')\n",
    "display(cv_results_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Siendo la gráfica que usamos para decidir los valores de los hiper-parámetros (mediante la regla de una desviación estándar), supongamos que cualquier valor que en su desviación cruce com la linea generada en color azul , e un valor a tener encuenta, tambien permitimos que visualizar el error minimo obtenido en verde:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5), ncols=1, nrows=1)\n",
    "ax.set_title(\"Error de Validacion (5-CV)\")\n",
    "\n",
    "ax.set_xlabel(\"Valor de k\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "subset = cv_results_uniform[cv_results_uniform['param_n_neighbors'] <= 120]\n",
    "ax.errorbar(subset['param_n_neighbors'],1 - subset['mean_test_score'],\n",
    "             subset['std_test_score'], label='default', capsize=3)  # 1 - [] para imprimir el error\n",
    "ax.hlines(y=1-threshold, xmin=0, xmax=120, colors='blue')\n",
    "\n",
    "ax.hlines(y=1-mejor_score, xmin=0, xmax=120, colors='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor que escogeríamos por tanto sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cv_results.loc[44:44, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cv_results.loc[73:73, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra la gráfica del error de test frente al valor del hiper-parámetro, y valora si la gráfica\n",
    "del error de entrenamiento con validación cruzada ha hecho una buena estimación del error de test.**¿Cuál es el error de test para el valor del hiper-parámetro seleccionado por la validación cruzada?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificación de nuestros hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto no se haría **JAMÁS** en una situación real.\n",
    "Pero como este es un ejemplo para aprender, vamos a ver cómo de lejos nos hemos quedado de los hiperparámetros \"ideales\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un Grid Search utilizando el conjunto de entrenamiento al completo (80% de los datos) y nuestro conjunto de validación va a ser el conjunto de test (20% de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Grid Search sin Cross Validation, únicamente con entrenamieto y validación (PredefinedSplit)\n",
    "\n",
    "# Creamos una lista con `-1` para los índices de entrenamiento y `0` para los índices de validación\n",
    "split_test_fold = [-1]*len(dataset_train_Y) + [0]*len(dataset_test_Y)\n",
    "ps = PredefinedSplit(test_fold=split_test_fold)\n",
    "\n",
    "# Juntamos los conjuntos de entrenamiento y test, fingiendo que son un sólo conjunto de entrenamiento-validación\n",
    "dataset_all_X_scaled = np.vstack([dataset_train_X_scaled, dataset_test_X_scaled])\n",
    "dataset_all_Y = pd.concat([dataset_train_Y, dataset_test_Y])\n",
    "\n",
    "k_neigh = KNeighborsClassifier()\n",
    "modelCV_test = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=ps,\n",
    "                       scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "np.random.seed(SEED_VALUE)  # Por como funciona KNN, no haría falta establecer semilla. Pero lo ponemos igualmente\n",
    "modelCV_test.fit(dataset_all_X_scaled, dataset_all_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(modelCV_test.cv_results_)\n",
    "test_results.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))  # Puedes cambiar estos valores según tus necesidades\n",
    "# eje x xantidad de vecinos y en el y cuanto es el errror\n",
    "plt.title(\"Error de validacion junto a error de test\")\n",
    "plt.errorbar(test_results['param_n_neighbors'],1 - test_results['mean_test_score'],\n",
    "             test_results['std_test_score'], label='test', capsize=3)  # 1 - [] para imprimir el error\n",
    "plt.errorbar(cv_results_uniform['param_n_neighbors'],1 - cv_results_uniform['mean_test_score'],\n",
    "             cv_results_uniform['std_test_score'], label='default', capsize=3) \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best_test = test_results[test_results['rank_test_score'] == 1].sort_values(by='param_n_neighbors')\n",
    "cv_results_best_test.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo selecionado con la validación cruzada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.loc[21:21, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo seleciondo con la regla de la desviación estandar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.loc[44:44, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.loc[73:73, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results.loc[17:26, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el 22 que era el supuesto mejor en trenamiento no dista mucho del score que saca el mejor en test por otro lado se observa que los mejores en test estan dentro de los modelos candidatos obtenidos por  la regla de una desviación estándar. por lo que podria decirse que entorno al 20-25 es donde se encuentra el minimo global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba a la hora de usar menos dimesiones\n",
    "\n",
    "Como se comentó anterior mente  exitste una relación entre 'Frequency' y 'Monetary' por lo que se quiere observar si al reducir las dimensiones eliminando Frequency o Monetary hay mejoras, baja el rendimiento o se comporta de manera similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_X_reduce = dataset_train.loc[:,[\"Reciente\",\"Frecuencia\",\"Tiempo\"]].astype(float)\n",
    "\n",
    "dataset_test_X_reduce = dataset_test.loc[:, [\"Reciente\",\"Frecuencia\",\"Tiempo\"]].astype(float)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(dataset_train_X_reduce)\n",
    "\n",
    "dataset_train_X_reduce_scaled = scaler.transform(dataset_train_X_reduce)\n",
    "dataset_test_X_reduce_scaled = scaler.transform(dataset_test_X_reduce)\n",
    "\n",
    "dataset_test_X_scaled\n",
    "\n",
    "# ('Numero de muestras:', 598) auque pone este valor al usar  GridSearchCV me indica que son 477\n",
    "print(\"Numero de muestras:\", n_samples)\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(1, 120, 1),\n",
    "    'n_jobs': [-1]  # Utilizar -1 para usar todos los procesadores disponibles y acelerar la búsqueda.\n",
    "}\n",
    "# hay\n",
    "k_neigh = KNeighborsClassifier()\n",
    "modelCV_reduce = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=5,\n",
    "                       scoring='accuracy', # parametro  top mejores en regresion mean scare error(skle pueda dar - std)\n",
    "                       return_train_score=True)  # El warning es normal, pues el ejemplo es demasiado pequeño\n",
    "\n",
    "np.random.seed(SEED_VALUE)  # Por como funciona KNN, no haría falta establecer una semilla. Pero lo ponemos igualmente\n",
    "modelCV_reduce.fit(dataset_train_X_reduce, dataset_train_Y)  # En KNN no hay aprendizaje en sí, pero hay que ejecutar este comando para poder hacer inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_reduce = pd.DataFrame(modelCV_reduce.cv_results_)\n",
    "cv_results.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Primera gráfica: De 0 a 110\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.title(\"Error de validacion (0 a 120)\")\n",
    "subset = cv_results_reduce[cv_results_reduce['param_n_neighbors'] <= 120]\n",
    "plt.errorbar(subset['param_n_neighbors'],1 - subset['mean_test_score'],\n",
    "             subset['std_test_score'], label='default', capsize=3)  # 1 - [] para imprimir el error\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota** Como podemos observar tiene un comportamiento similar que usar la variable comprobemos el resto de pasos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results_reduce[cv_results_reduce['rank_test_score'] == 1].sort_values(by='param_n_neighbors')\n",
    "cv_results_best.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplicar la regla de una desviación estándar\n",
    "best_model = cv_results_reduce[cv_results_reduce['rank_test_score'] == 1].sort_values(by='param_n_neighbors').iloc[0]\n",
    "mejor_score = best_model['mean_test_score']\n",
    "mejor_std = best_model['std_test_score']\n",
    "\n",
    "\n",
    "threshold =  mejor_score -  mejor_std\n",
    "\n",
    "cv_results_aux = cv_results[\n",
    "     cv_results['mean_test_score']>= threshold\n",
    "].sort_values(by='param_n_neighbors', ascending=False)\n",
    "\n",
    "cv_results_aux = cv_results_aux.loc[:, [\n",
    "    'param_n_neighbors',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'rank_test_score'\n",
    "    ]\n",
    "]\n",
    "\n",
    "cv_results_aux = cv_results_aux.sort_values(by='param_n_neighbors',ascending=False)\n",
    "cv_results_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Grid Search sin Cross Validation, únicamente con entrenamieto y validación (PredefinedSplit)\n",
    "\n",
    "# Creamos una lista con `-1` para los índices de entrenamiento y `0` para los índices de validación\n",
    "split_test_fold = [-1]*len(dataset_train_Y) + [0]*len(dataset_test_Y)\n",
    "ps = PredefinedSplit(test_fold=split_test_fold)\n",
    "\n",
    "# Juntamos los conjuntos de entrenamiento y test, fingiendo que son un sólo conjunto de entrenamiento-validación\n",
    "dataset_all_X_scaled = np.vstack([dataset_train_X_reduce_scaled, dataset_test_X_reduce_scaled])\n",
    "dataset_all_Y = pd.concat([dataset_train_Y, dataset_test_Y])\n",
    "\n",
    "k_neigh = KNeighborsClassifier()\n",
    "modelCV_test_reduce = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=ps,\n",
    "                       scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "np.random.seed(SEED_VALUE)  # Por como funciona KNN, no haría falta establecer semilla. Pero lo ponemos igualmente\n",
    "modelCV_test_reduce.fit(dataset_all_X_scaled, dataset_all_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_reduce = pd.DataFrame(modelCV_test_reduce.cv_results_)\n",
    "#test_results.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.title(\"Error de validacion (0 a 120)\")\n",
    "\n",
    "subset_reduce = cv_results_reduce[test_results_reduce['param_n_neighbors'] <= 120]\n",
    "\n",
    "subset_test_reduce= test_results_reduce[test_results['param_n_neighbors']<= 120]\n",
    "\n",
    "subset = cv_results[cv_results['param_n_neighbors'] <= 120]\n",
    "\n",
    "subset_test= test_results[test_results['param_n_neighbors']<= 120]\n",
    "\n",
    "plt.errorbar(subset_test['param_n_neighbors'],1 - subset_test['mean_test_score'],\n",
    "             subset_test['std_test_score'], label='test', capsize=3,alpha=0.6,  color='blue',linestyle='--')  # 1 - [] para imprimir el error\n",
    "\n",
    "plt.errorbar(subset['param_n_neighbors'],1 - subset['mean_test_score'],\n",
    "             subset['std_test_score'], label='train', capsize=3,alpha=0.3, color='red', )  # 1 - [] para imprimir el error\n",
    "\n",
    "plt.errorbar(subset_test_reduce['param_n_neighbors'],1 - subset_test_reduce['mean_test_score'],\n",
    "             subset_test_reduce['std_test_score'], label='train', capsize=3,alpha=0.6,  color='green', linestyle='--')  # 1 - [] para imprimir el error\n",
    "\n",
    "plt.errorbar(subset_reduce['param_n_neighbors'],1 - subset_reduce['mean_test_score'],\n",
    "             subset_reduce['std_test_score'], label='train', capsize=3,alpha=0.3, color='purple')  # 1 - [] para imprimir el error\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best_test = subset_test_reduce[subset_test_reduce['rank_test_score'] == 1].sort_values(by='param_n_neighbors')\n",
    "cv_results_best_test.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo selecionado por validación cruzada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_reduce.loc[20:20, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo selecionado por regla de la desviación estándar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_reduce.loc[71:71, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos casos comprobamos que los modelos selecionados empeoran entre 1.4 % en comparación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamdo si se encuentra un minimo global entre el 20 y el 26 o entorno al 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_reduce.loc[19:26, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_reduce.loc[38:45, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con el de usar todos los modelos hay cierta mejora permitiendo que haya una mayor simplificación del modelo ya que al usar mas vecino suavizamos la frontera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercio 3.\n",
    "\n",
    "Repite el ejercicio 2 pero para el problema de regresión [Energy Efficiency](https://archive.ics.uci.edu/dataset/242/energy+efficiency) con la variable de salida\n",
    "cooling load. Al ser un problema de regresión deberás utilizar KNeighborsRegressor, y como medida\n",
    "de error de entrenamiento y test el MSE.\n",
    "\n",
    "Nota. Al ser un problema de regresión, para estimar tanto el error de entrenamiento como el de\n",
    "test (MSE) es necesario desestandarizar los errores calculados. Para desestandarizar el campo\n",
    "`mean_test_score`, únicamente será necesario multiplicar cada valor por la varianza (cuadrado de la\n",
    "desviación estándar) de las observaciones de Y del conjunto de entrenamiento. No se debe restar la\n",
    "media, ya que los campos `splitX_test_score` se calculan como la diferencia entre el valor de\n",
    "groundtruth y la predicción para cada dato de test, por lo que todas las operaciones de adición o\n",
    "substracción ya se han tenido en cuenta. De forma similar, para desestandarizar el campo\n",
    "`std_test_score`, únicamente será necesario multiplicar cada valor por la varianza de las\n",
    "observaciones de Y del conjunto de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_ENERGY='./data/energy+efficiency/EnergyEfficiency.data'\n",
    "# Leer el archivo de datos y obtener la primera fila como nombres de columnas\n",
    "data = pd.read_csv(DATASET_ENERGY)\n",
    "NAME_ENERGY = data.columns.tolist()\n",
    "#print(NAME_ENERGY)\n",
    "#NAME_ENERGY=[\"Reciente\",\"Frecuencia\",\"Cantidad_Sangre\",\"Tiempo\",\"Donacion_marzo\"]\n",
    "\n",
    "\n",
    "if os.path.exists(DATASET_ENERGY):\n",
    "    dataset_energy = pd.read_csv(DATASET_ENERGY, \n",
    "                          delimiter=DATASET_DELIMITER,\n",
    "                          header=None,\n",
    "                          skiprows=1,\n",
    "                          names = NAME_ENERGY)\n",
    "else:\n",
    "    dataset_energy = d.DataFrame(np.array(\n",
    "    [[0, 3, 2, 1], \n",
    "    [3, 0, 3, 0], \n",
    "    [0, 3, -1, 0], \n",
    "    [3, 0, 0, 1], \n",
    "    [1, 2, 1, 1], \n",
    "    [2, 1, 0, 0]]), columns=['X1', 'X2', 'X3', 'Y'])\n",
    "    \n",
    "dataset_energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tipo del dato de cada columna:')\n",
    "print(dataset.dtypes)\n",
    "# Comprobamos si hay nan\n",
    "print(\"\\n Cantidad de valores NaN en cada columna:\")\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir la columna de la etiqueta\n",
    "columns = dataset_energy.columns[:-1]\n",
    "\n",
    "# Crear una cuadrícula de subtramas 2x4 para histogramas y gráficos de dispersión\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 5))\n",
    "\n",
    "# Visualizar histogramas para todas las columnas\n",
    "for i, column in enumerate(columns):\n",
    "    row = i // 4  # Determinar la fila de la subtrama\n",
    "    col = i % 4   # Determinar la columna de la subtrama\n",
    "    axs[row, col].hist(dataset_energy[column], bins=20, alpha=0.7)\n",
    "    axs[row, col].set_title(\"Histogram of {}\".format(column))\n",
    "# Ajustar el diseño\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear todas las combinaciones posibles de pares de variables\n",
    "combinations = list(itertools.combinations(columns, 2))\n",
    "\n",
    "num_cols=4\n",
    "# Calcular el número de filas necesario para acomodar todas las combinaciones\n",
    "num_combinations = len(combinations)\n",
    "num_rows = num_combinations // num_cols + (num_combinations % num_cols > 0)\n",
    "\n",
    "# Crear una cuadrícula de subtramas con un número suficiente de filas para todas las combinaciones\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 5))  # Ajustar el tamaño de figura según sea necesario\n",
    "\n",
    "# Visualizar gráficos de dispersión para todas las combinaciones\n",
    "for j, (var1, var2) in enumerate(combinations):\n",
    "    row = j // num_cols\n",
    "    col = j % num_cols\n",
    "    axs[row, col].scatter(dataset_energy[var1], \n",
    "                          dataset_energy[var2], \n",
    "                          c='red')\n",
    "    axs[row, col].set_title(\"{} vs {}\".format(var1, var2))\n",
    "    axs[row, col].set_xlabel(var1)\n",
    "    axs[row, col].set_ylabel(var2)\n",
    "\n",
    "# Ajustar el diseño para que no haya superposición\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar una cierta relación inversamente proporcional entre X1 Y X2  para otras variables no se opserva relaciones entre ellas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor en scikit-learn\n",
    "\n",
    "El `sklearn.neighbors.KNeighborsRegressor` es un regresor que implementa la regresión basada en los k-vecinos más cercanos.\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- **n_neighbors** (int, default=5): Número de vecinos a utilizar.\n",
    "- **weights** ({'uniform', 'distance'} o callable, default='uniform'): Función de peso utilizada en la predicción.\n",
    "- **algorithm** ({'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'): Algoritmo para calcular los vecinos más cercanos.\n",
    "- **leaf_size** (int, default=30): Tamaño de hoja para BallTree o KDTree.\n",
    "- **p** (float, default=2): Parámetro de potencia para la métrica de Minkowski.\n",
    "- **metric** (str o callable, default='minkowski'): Métrica de distancia a utilizar.\n",
    "- **metric_params** (dict, default=None): Argumentos adicionales para la función métrica.\n",
    "- **n_jobs** (int, default=None): Número de trabajos paralelos para la búsqueda de vecinos.\n",
    "\n",
    "### Métodos\n",
    "\n",
    "- **fit(X, y)**: Ajustar el modelo a los datos de entrenamiento.\n",
    "- **get_params([deep])**: Obtener los parámetros del estimador.\n",
    "- **kneighbors([X, n_neighbors, return_distance])**: Encontrar los K-vecinos de un punto.\n",
    "- **kneighbors_graph([X, n_neighbors, mode])**: Calcular el grafo de k-Vecinos.\n",
    "- **predict(X)**: Predecir los valores objetivo.\n",
    "- **score(X, y[, sample_weight])**: Coeficiente de determinación \\( R^2 \\) de la predicción.\n",
    "- **set_params(**params)**: Establecer los parámetros del estimador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División de los datos en entrenamiento (80%) y test (20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train_energy, dataset_test_energy = train_test_split(dataset_energy,\n",
    "                            test_size=0.2, random_state=SEED_VALUE,\n",
    "                                    )\n",
    "dataset_test_energy.loc[:,columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso no es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imp = SimpleImputer(missing_values=np.nan, fill_value='mean')\n",
    "#imp = imp.fit(dataset_train_energy)  # La media la calculamos SÓLO a partir del conjunto de train\n",
    "\n",
    "# Los valores van a ser los mismos que antes, pues no tenemos datos faltantes\n",
    "#dataset_train_prep_energy = imp.transform(dataset_train_energy)\n",
    "#dataset_test_prep_energy = imp.transform(dataset_test_energy)\n",
    "\n",
    "#dataset_test_prep_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#dataset_train_energy = pd.DataFrame(dataset_train_prep_energy,\n",
    "#                             columns=dataset_train_energy.columns,\n",
    "#                             index=dataset_train_energy.index)\n",
    "#dataset_test_energy = pd.DataFrame(dataset_test_prep_energy,\n",
    "#                            columns=dataset_test_energy.columns,\n",
    "#                            index=dataset_test_energy.index)\n",
    "\n",
    "#dataset_test_energy.loc[:,columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización de los datos**\n",
    "\n",
    "Esto hay que hacerlo **ANTES** de dividir en conjuntos de entrenamiento y test. Además, como es un problema de **regresion**, estandarizaremos la variable dependientetambien .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(dataset_train_energy)\n",
    "\n",
    "dataset_train_scaled_energy = scaler.transform(dataset_train_energy)\n",
    "\n",
    "dataset_test_scaled_energy = scaler.transform(dataset_test_energy)\n",
    "\n",
    "dataset_test_scaled_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"mean [X1, X2, X3, X4, X5, X6, X7, X8, Y1,Y2]: {}\".format(scaler.mean_))\n",
    "print(\"std [X1, X2, X3, X4, X5, X6, X7, X8, Y1,Y2]: {}\".format(scaler.scale_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train_scaled_energy = pd.DataFrame(dataset_train_scaled_energy,\n",
    "                             columns=dataset_train_energy.columns,\n",
    "                             index=dataset_train_energy.index)\n",
    "dataset_test_scaled_energy = pd.DataFrame(dataset_test_scaled_energy,\n",
    "                            columns=dataset_test_energy.columns,\n",
    "                            index=dataset_test_energy.index)\n",
    "\n",
    "\n",
    "dataset_test_scaled_energy.loc[:,columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SEPARAMOS LAS VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train_X_energy = dataset_train_scaled_energy.loc[:, NAME_ENERGY[:-1]].astype(float)\n",
    "dataset_train_Y_energy = dataset_train_scaled_energy.loc[:, NAME_ENERGY[-1]]\n",
    "dataset_train_X_energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_test_X_energy = dataset_test_scaled_energy.loc[:, NAME_ENERGY[:-1]].astype(float)\n",
    "dataset_test_Y_energy = dataset_test_scaled_energy.loc[:, NAME_ENERGY[-1]]\n",
    "\n",
    "dataset_test_Y_energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected n_neighbors <= n_samples,  but n_samples = 491, n_neighbors = 492\n",
    "# Expected n_neighbors <= n_samples,  n_samples = 477\n",
    "# Si solo necesitas el número de muestras\n",
    "n_samples = dataset_train_X_energy.shape[0]\n",
    "\n",
    "# ('Numero de muestras:', 614) auque pone este valor al usar  GridSearchCV me indica que son 491\n",
    "print(\"Numero de muestras:\", n_samples)\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(1, 491, 1),\n",
    "    'n_jobs': [-1]  # Utilizar -1 para usar todos los procesadores disponibles y acelerar la búsqueda.\n",
    "}\n",
    "# hay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_X_energy.index.equals(dataset_train_Y_energy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh = KNeighborsRegressor()\n",
    "modelCV_energy = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=5,\n",
    "                       scoring=\"neg_mean_squared_error\",\n",
    "                       return_train_score=True)\n",
    "\n",
    "# Por como funciona KNN, no haría falta establecer una semilla. Pero lo ponemos igualmente\n",
    "np.random.seed(SEED_VALUE)\n",
    "\n",
    "# En KNN no hay aprendizaje en sí, pero hay que ejecutar este comando para poder hacer inferencias\n",
    "modelCV_energy.fit(dataset_train_X_energy, dataset_train_Y_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results_energy = pd.DataFrame(modelCV_energy.cv_results_)\n",
    "cv_results_energy.loc[:, [ 'param_n_neighbors', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "cv_results_energy['destandardized_mean_test_score'] = (-1) * cv_results_energy['mean_test_score'] * (scaler.scale_[8]**2)\n",
    "cv_results_energy['destandardized_std_test_score'] = cv_results_energy['std_test_score'] * (scaler.scale_[8]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results_energy[cv_results_energy['rank_test_score'] == 1]\n",
    "colums_selected= [ 'param_n_neighbors', 'mean_test_score', 'std_test_score'\n",
    "                        ,'destandardized_mean_test_score','destandardized_std_test_score','rank_test_score']\n",
    "cv_results_best.loc[:, colums_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los pesos basados en cada \n",
    "cv_results_uniform = cv_results\n",
    "\n",
    "plt.figure(figsize=(16, 5))  # Puedes cambiar estos valores según tus necesidades\n",
    "# eje x xantidad de vecinos y en el y cuanto es el errror\n",
    "plt.title(\"Error de validacion\")\n",
    "plt.errorbar(cv_results_energy['param_n_neighbors'],cv_results_energy['destandardized_mean_test_score'],\n",
    "             cv_results_energy['destandardized_std_test_score'], label='default', capsize=3)  # 1 - [] para imprimir el error\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results_energy[cv_results_energy['rank_test_score'] == 1]\n",
    "cv_results_best.loc[:, colums_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera gráfica: De 0 a 110\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.title(\"Error de validacion (0 a 120)\")\n",
    "subset = cv_results_energy[cv_results_energy['param_n_neighbors'] <= 120]\n",
    "plt.errorbar(subset['param_n_neighbors'],subset['destandardized_mean_test_score'],\n",
    "             subset['destandardized_std_test_score'], label='default', capsize=3)  # 1 - [] para imprimir el error\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_best = cv_results_energy\n",
    "cv_results_best.loc[:,colums_selected].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la regla de una desviación estándar\n",
    "best_model = cv_results_energy[cv_results_energy['rank_test_score'] == 1].sort_values(by='param_n_neighbors').iloc[0]\n",
    "mejor_score = best_model['destandardized_mean_test_score']\n",
    "mejor_std = best_model['destandardized_std_test_score']\n",
    "\n",
    "threshold_energy=mejor_score+mejor_std\n",
    "print(threshold_energy)\n",
    "cv_results_aux = cv_results_energy[\n",
    "     cv_results_energy['destandardized_mean_test_score']<=threshold_energy\n",
    "].sort_values(by='param_n_neighbors', ascending=False)\n",
    "\n",
    "cv_results_aux = cv_results_aux.loc[:, colums_selected]\n",
    "\n",
    "cv_results_aux = cv_results_aux.sort_values(by='param_n_neighbors')\n",
    "cv_results_aux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se el valor que se obtiene como el mejor y el que da el la regla de una desviación estándar seria la misma cantidad de neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Grid Search sin Cross Validation, únicamente con entrenamieto y validación (PredefinedSplit)\n",
    "\n",
    "# Creamos una lista con `-1` para los índices de entrenamiento y `0` para los índices de validación\n",
    "split_test_fold = [-1]*len(dataset_train_Y_energy) + [0]*len(dataset_test_Y_energy)\n",
    "ps = PredefinedSplit(test_fold=split_test_fold)\n",
    "\n",
    "# Juntamos los conjuntos de entrenamiento y test, fingiendo que son un sólo conjunto de entrenamiento-validación\n",
    "dataset_all_X_scaled = np.vstack([dataset_train_X_energy, dataset_test_X_energy])\n",
    "dataset_all_Y = pd.concat([dataset_train_Y_energy, dataset_test_Y_energy])\n",
    "\n",
    "k_neigh = KNeighborsRegressor()\n",
    "modelCV_test_energy = GridSearchCV(k_neigh,\n",
    "                       hyperparameters,\n",
    "                       cv=ps,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       return_train_score=True)\n",
    "\n",
    "np.random.seed(SEED_VALUE)  # Por como funciona KNN, no haría falta establecer semilla. Pero lo ponemos igualmente\n",
    "modelCV_test_energy.fit(dataset_all_X_scaled, dataset_all_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results_energy = pd.DataFrame(modelCV_test_energy.cv_results_)\n",
    "test_results_energy['destandardized_mean_test_score'] = (-1) * test_results_energy['mean_test_score'] * (scaler.scale_[8]**2)\n",
    "test_results_energy['destandardized_std_test_score'] = test_results_energy['std_test_score'] * (scaler.scale_[8]**2)\n",
    "test_results_energy.loc[:, colums_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.title(\"Error de validacion (0 a 120)\")\n",
    "subset = cv_results_energy[cv_results_energy['param_n_neighbors'] <= 120]\n",
    "subset_test= test_results_energy[test_results_energy['param_n_neighbors']<= 120]\n",
    "plt.errorbar(subset_test['param_n_neighbors'],subset_test['destandardized_mean_test_score'],\n",
    "             subset_test['destandardized_std_test_score'], label='test', capsize=3)  # 1 - [] para imprimir el error\n",
    "\n",
    "plt.errorbar(subset['param_n_neighbors'],subset['destandardized_mean_test_score'],\n",
    "             subset['destandardized_std_test_score'], label='train', capsize=3,alpha=0.5)  # 1 - [] para imprimir el error\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_energy.loc[:, colums_selected].sort_values(by='destandardized_mean_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_energy.loc[1:1, colums_selected].sort_values(by='destandardized_mean_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el valor que selencionamos bastante diferencia con el modelo que mejores valores obtenido en el test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
